#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

mod utils;
mod converter;

use converter::{
    extract_midi_notes, allocate_voices_smart, generate_mml_final,
    Note, TPB,
};

#[derive(Debug, Serialize, Deserialize)]
struct ConversionOptions {
    mode: String, // "normal" or "instrument"
    char_limit: usize,
    compress_mode: bool, // true: 글자수 우선 (점음표/타이 최소화), false: 정확도 우선
}

#[derive(Debug, Serialize, Deserialize)]
struct VoiceResult {
    name: String,
    content: String,
    char_count: usize,
    note_count: usize,
    duration: f64,
}

#[derive(Debug, Serialize, Deserialize)]
struct ConversionResult {
    success: bool,
    voices: Vec<VoiceResult>,
    error: Option<String>,
    bpm: u32,
    total_notes: usize,
}

#[tauri::command]
fn convert_midi(midi_data: Vec<u8>, options: ConversionOptions) -> ConversionResult {
    match convert_midi_internal(&midi_data, &options) {
        Ok(result) => result,
        Err(e) => ConversionResult {
            success: false,
            voices: vec![],
            error: Some(e),
            bpm: 0,
            total_notes: 0,
        },
    }
}

fn convert_midi_internal(
    midi_data: &[u8],
    options: &ConversionOptions,
) -> Result<ConversionResult, String> {
    let (notes, bpm) = extract_midi_notes(midi_data, 24)?;
    let total_notes = notes.len();

    let voices = if options.mode == "instrument" {
        // 악기별 모드
        convert_by_instrument(notes, bpm, options.char_limit, options.compress_mode)?
    } else {
        // 일반 모드 (피치별)
        convert_by_pitch(notes, bpm, options.char_limit, options.compress_mode)?
    };

    Ok(ConversionResult {
        success: true,
        voices,
        error: None,
        bpm,
        total_notes,
    })
}

fn convert_by_pitch(
    notes: Vec<Note>,
    bpm: u32,
    char_limit: usize,
    compress_mode: bool,
) -> Result<Vec<VoiceResult>, String> {
    let voices = allocate_voices_smart(notes);
    
    // 빈 voice 제거
    let voices: Vec<Vec<Note>> = voices.into_iter()
        .filter(|v| !v.is_empty())
        .collect();
    
    if voices.is_empty() {
        return Ok(Vec::new());
    }
    
    // 최대 end_time 찾기
    let max_end_time = voices.iter()
        .flat_map(|v| v.iter())
        .map(|n| n.end)
        .max()
        .unwrap_or(0);
    
    if max_end_time == 0 {
        return Ok(Vec::new());
    }
    
    // 이진 탐색으로 모든 voice가 char_limit 이하인 최대 end_time 찾기
    let grid_size = 24u32;
    let mut left = 0u32;
    let mut right = max_end_time;
    let mut best_end_time = max_end_time;
    
    while left <= right {
        let mid = ((left + right) / 2 / grid_size) * grid_size;
        
        let mut all_valid = true;
        
        // 각 voice를 mid 시간까지 크롭해서 char_limit 체크
        for voice in voices.iter() {
            let cropped: Vec<Note> = voice.iter()
                .filter(|n| n.start < mid)
                .cloned()
                .collect();
            
            if cropped.is_empty() {
                continue;
            }
            
            let first_note = cropped[0].note;
            let mut start_octave = (first_note as i32 / 12) - 1;
            start_octave = start_octave.max(2).min(6);
            
            let mml = generate_mml_final(&cropped, bpm, start_octave, compress_mode);
            
            if mml.len() > char_limit {
                all_valid = false;
                break;
            }
        }
        
        if all_valid {
            best_end_time = mid;
            left = mid + grid_size;
        } else {
            right = mid - grid_size;
        }
    }
    
    // best_end_time으로 모든 voice 최종 크롭
    let mut results = Vec::new();
    for (idx, voice) in voices.iter().enumerate() {
        let final_voice: Vec<Note> = voice.iter()
            .filter(|n| n.start < best_end_time)
            .cloned()
            .collect();
        
        if final_voice.is_empty() {
            continue;
        }

        let first_note = final_voice[0].note;
        let mut start_octave = (first_note as i32 / 12) - 1;
        start_octave = start_octave.max(2).min(6);

        let mml_code = generate_mml_final(&final_voice, bpm, start_octave, compress_mode);
        let note_count = final_voice.len();
        let end_time = best_end_time as f64 / TPB as f64 / 2.0;

        let name = if idx == 0 {
            "멜로디".to_string()
        } else {
            format!("화음{}", idx)
        };

        results.push(VoiceResult {
            name,
            content: mml_code.clone(),
            char_count: mml_code.len(),
            note_count,
            duration: end_time,
        });
    }

    Ok(results)
}

fn convert_by_instrument(
    notes: Vec<Note>,
    bpm: u32,
    char_limit: usize,
    compress_mode: bool,
) -> Result<Vec<VoiceResult>, String> {
    let mut instrument_groups: HashMap<String, Vec<Note>> = HashMap::new();
    for note in notes {
        instrument_groups
            .entry(note.instrument.clone())
            .or_insert_with(Vec::new)
            .push(note);
    }

    let mut instrument_names: Vec<String> = instrument_groups.keys().cloned().collect();
    instrument_names.sort();

    // 모든 악기의 voice 수집
    let mut all_voices = Vec::new();
    let mut voice_instrument_map = Vec::new();
    
    for instrument_name in &instrument_names {
        let instrument_notes = instrument_groups.get(instrument_name).unwrap();
        let voices = allocate_voices_smart(instrument_notes.clone());

        for voice in voices.into_iter() {
            if !voice.is_empty() {
                all_voices.push(voice);
                voice_instrument_map.push(instrument_name.clone());
            }
        }
    }
    
    if all_voices.is_empty() {
        return Ok(Vec::new());
    }
    
    // 최대 end_time 찾기
    let max_end_time = all_voices.iter()
        .flat_map(|v| v.iter())
        .map(|n| n.end)
        .max()
        .unwrap_or(0);
    
    if max_end_time == 0 {
        return Ok(Vec::new());
    }
    
    // 이진 탐색으로 모든 voice가 char_limit 이하인 최대 end_time 찾기
    let grid_size = 24u32;
    let mut left = 0u32;
    let mut right = max_end_time;
    let mut best_end_time = max_end_time;
    
    while left <= right {
        let mid = ((left + right) / 2 / grid_size) * grid_size;
        
        let mut all_valid = true;
        
        // 각 voice를 mid 시간까지 크롭해서 char_limit 체크
        for voice in all_voices.iter() {
            let cropped: Vec<Note> = voice.iter()
                .filter(|n| n.start < mid)
                .cloned()
                .collect();
            
            if cropped.is_empty() {
                continue;
            }
            
            let first_note = cropped[0].note;
            let mut start_octave = (first_note as i32 / 12) - 1;
            start_octave = start_octave.max(2).min(6);
            
            let mml = generate_mml_final(&cropped, bpm, start_octave, compress_mode);
            
            if mml.len() > char_limit {
                all_valid = false;
                break;
            }
        }
        
        if all_valid {
            best_end_time = mid;
            left = mid + grid_size;
        } else {
            right = mid - grid_size;
        }
    }
    
    // best_end_time으로 모든 voice 최종 크롭
    let mut results = Vec::new();
    for (idx, (voice, instrument_name)) in all_voices.iter().zip(voice_instrument_map.iter()).enumerate() {
        let final_voice: Vec<Note> = voice.iter()
            .filter(|n| n.start < best_end_time)
            .cloned()
            .collect();
        
        if final_voice.is_empty() {
            continue;
        }

        let first_note = final_voice[0].note;
        let mut start_octave = (first_note as i32 / 12) - 1;
        start_octave = start_octave.max(2).min(6);

        let mml_code = generate_mml_final(&final_voice, bpm, start_octave, compress_mode);
        let note_count = final_voice.len();
        let end_time = best_end_time as f64 / TPB as f64 / 2.0;

        let name = if idx == 0 {
            format!("멜로디 ({})", instrument_name)
        } else {
            format!("화음{} ({})", idx, instrument_name)
        };

        results.push(VoiceResult {
            name,
            content: mml_code.clone(),
            char_count: mml_code.len(),
            note_count,
            duration: end_time,
        });
    }

    Ok(results)
}

fn main() {
    tauri::Builder::default()
        .plugin(tauri_plugin_fs::init())
        .plugin(tauri_plugin_dialog::init())
        .invoke_handler(tauri::generate_handler![convert_midi])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}